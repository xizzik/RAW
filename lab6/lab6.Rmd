---
title: "Regresja i analiza wariancji - Laboratorium 6"
subtitle: 'Jednoczynnikowa analiza wariancji - ciąg dalszy' 
author: 
  name: 'Adrian Kowalski'
  affiliation: 'Politechnika Krakowska'
output: html_notebook
---

# Analiza wariancji, a regresja liniowa

```{r}
library(tidyverse)
data1 <- readr::read_csv('danec2a.csv')
summary(data1)
```
```{r}
unique(data1$System)
```
```{r}
data1[-c(1,3)] <- zoo::na.aggregate(data1[-c(1,3)])
summary(data1)
```


```{r}
anova1 <- aov(H ~ System ,data = data1)
summary(anova1)
```

```{r}
reg1 <- lm(H ~ System, data = data1)
summary(reg1)
```
```{r}
model2 <- lm(H ~ Vstrz, data = data1)
model3 <- lm(H ~ Vstrz + Vgal, data = data1)
summary(model2)
```

```{r}
summary(model3)
```
```{r}
anova(model2, model3)
```

```{r}
anova(reg1)
```
# Test Bartletta i Levene

Ważnym założeniem klasycznej analizy wariancji jest stała wariancja w każdej z grup. To założenie możemy przetestować za pomocą testu Bartletta. Hipotezą zerową testu Bartletta jest $H_0: \sigma^2_1 = \sigma^2_2 = \dots = \sigma^2_k$, że w każdej z $k$ grup wariancja jest równa. Hipotezą alternatywną jest, że conajmniej jedna z wariancji różni się od pozostałych. Statystyka testowa testu Bartleta ma rozkład zwany rozkładem $K^2$, który można przybliżać za pomocą rozkładu $\chi^2$ o $k-1$ stopniach swobody. Ważnym założeniem przy wyprowadzaniu tego rozkładu jest fakt, że nasze populacje pochodzą z rozkładu normalnego.

```{r}
bartlett.test(H ~ System, data = data1)
```
W przypadku, gdy spotykamy się z populacjami, które nie mają rozkładu normalnego mamy alternatywny test do testu Bartletta - test Levene'a. Hipotezą zerowa i alternatywna testu jest identyczna jak w teście Bartletta. Jest on bardzo mocno powiązany z analizą wariancji, a jego statystyka testowa ma rozkład (w przybliżeniu) $F$ o $k-1$ i $n-k$ stopniach swobody.
```{r}
library(car)
leveneTest(H ~ System, data = data1)
```


# Poprawka Welscha dla Analizy Wariancji

W praktyce bardzo trudno jest spełnić założenie o równej wariancji między grupami. Na szczęście mamy narzędzie służące do przeprowadzenia analizy wariancji w tej sytuacji. Jest to tzw. Analiza Wariancji Welscha, lub z poprawką Welscha (podobnie jak przy teście $t$). 

```{r}
oneway.test(H ~ System, data = data1)
```
Nie możemy też użyć procedury Tukeya do analizy post-hoc, ale na szczęście tutaj również mamy alternatywę nie zakładającą stałej wariancji. Jest to test Gamesa-Howella, który znajdziemy w pakiecie \textit{rstatix}.
```{r}
library(rstatix)
ghTest1 <- rstatix::games_howell_test(H ~ System, data = data1)
ghTest1 <- ghTest1 %>% dplyr::mutate(gr_label = paste(group1,group2, sep='-')) %>% dplyr::mutate(order = row_number())
ghTest1
```

```{r}
ggplot(ghTest1, aes(x=estimate, y = order)) +  geom_linerange(aes(xmin = conf.low, xmax = conf.high)) + geom_point() + scale_y_discrete(name = '', limits = as.factor(ghTest1$order), labels = ghTest1$gr_label) + geom_vline(xintercept = 0, color = 'red', linetype = 'dashed')
```
# Alternatywa nieparametryczna - test Kruskalla-Wallisa

Nieparametryczną alternatywą jednoczynnikowej analizy wariancji jest test Kruskala-Wallisa. Nie wymaga on już założenia o normalności rozkładów testowanych populacji, ani założenia o stałej wariancji pomiędzy grupami. Działa on na bazie median, jest to przykład tzw. testu na rangach. Hipoteza zerowa tego testu sprowadza się do odpowiedzi na pytanie czy dane pochodzą z tego samego rozkładu (formalnie - mediana każdej z grup jest sobie równa). Rozkład statystyki $H$ przybliża się za pomocą rozkładu $\chi^2$.

```{r}
kruskal.test(H ~ System, data = data1)
```
Do analizy post-hoc w tym wypadku używamy tzw. testu Dunna.

```{r}
library(FSA)
FSA::dunnTest(H ~ System, data = data1)
```
# Uwaga: Poprawka Bonferroniego

W wielu przypadkach powyżej zaobserwowaliśmy tzw. $p$-adjusted, czyli poprawioną $p$-wartość. Jest to związane z faktem, że gdy wykonujemy testy, których wyniki zależą od siebie, tak jak procedura Tukeya lub test Dunna, to prawdopodobieństwo popełnienia błędu pierwszego rodzaju z tych testów kumuluje się. Walczymy z tym za pomocą poprawki Bonferoniego. Jeżeli $m$ to ilość zparowanych w takim sensie jak powyżej testów, które wykonujemy to, aby skożystać z poprawki Bonferroniego ustalamy nasz poziom istotności $\overline{alpha} = \frac{\alpha}{m}$ lub mnożymy $p_{adj} = m*p$. Nie jest to jedyna poprawka $p$-wartości jaką możemy stosować, ale jest ona dość prosta w wyprowadzeniu. Faktycznie, niech $FWER$ oznacza poziom błędu w całej rodzinie testów przez nas przeprowadzanych, $p_i$ będzie $p$-wartością $i$-tego testu, a $m_0$ niech będzie wartością prawdziwych hipotez zerowych (zauważmy, że nie znamy tej liczby). Wtedy \[ FWER = \mathbb{P} \left( \bigcup_{i=1}^{m_0}\left(p_i \leq \frac{\alpha}{m} \right) \right) \leq \sum_{i=1}^{m_0} \mathbb{P} \left(  p_i \leq \frac{\alpha}{m}\right) = m_0 \frac{\alpha}{m} \leq \alpha.\]

# Ćwiczenie 1

W pliku danec2a.xlsx znajdują się dane biometryczne drzewek z 7-letniej
plantacji sosnowej założonej z sadzonek wyprodukowanych z odkrytym systemem
korzeniowym (System - Odkryty), sadzonek wyprodukowanych w szkółce
kontenerowej z zakrytym systemem korzeniowym bez mikoryzacji (System - Con)
oraz mikoryzowanych grzybami Hebeloma (System - Heb) i Lacaria (System - Lac).
Zbadaj czy system produkcji sadzonek wpływa na wysokość (H) i grubość (D0) 7-
letnich sosen?

Zbadaj czy system produkcji sadzonek wykorzystanych do założenia plantacji ma
wpływ na wielkość nadziemnej biomasy 7-letnich sosen?

```{r}
danec2a <- readr::read_csv('danec2a.csv')
head(danec2a)
```
```{r}
unique(danec2a$System)
```
```{r}
mask <- danec2a$System == "Odkryty"
#hist(danec2a$D0[mask])
shapiro.test(danec2a$D0[mask])
```
```{r}
mask <- danec2a$System == "Con"
#hist(danec2a$D0[mask])
shapiro.test(danec2a$D0[mask])
```
```{r}
mask <- danec2a$System == "Heb"
#hist(danec2a$D0[mask])
shapiro.test(danec2a$D0[mask])
```
```{r}
mask <- danec2a$System == "Lac"
#hist(danec2a$D0[mask])
shapiro.test(danec2a$D0[mask])
```
```{r}
bartlett.test(D0 ~ System, data=danec2a)
```
```{r}
summary(aov(D0 ~ System, data=danec2a))
```
System ma wpływ na grubość.

```{r}
plot(TukeyHSD(aov(D0 ~ System, data=danec2a)))
```
```{r}
TukeyHSD(aov(D0 ~ System, data=danec2a))
```
# Ćwiczenie 2

Korzystając z danych zawartych w pliku danec3.xlsx zbadaj, czy wiek ma
wpływ na długość czaszki saren. Analizy przeprowadź oddzielnie dla poszczególnych
rodzajów obwodów łowieckich.

Zbadaj wpływ wieku na szerokość czaszki saren (analizy oddzielnie dla rodzajów
obwodów).

Zbadaj czy rodzaj obwodu ma istotny wpływ na masę poroża saren (analizy oddzielne
dla klas wieku).

```{r}
danec2 <- readr::read_csv('danec2.csv')
head(danec2)
```

# Ćwiczenie 3

Korzystając z danych zawartych w pliku DL_dane_cw2.xlsx sprawdź czy
analizowane drzewostany różnią się istotnie pod względem długości koron (LK).

Sprawdź czy analizowane drzewostany różnią się pod względem względnej długości
koron (LKw).

Porównaj średnie wysokości drzew w analizowanych drzewostanach.

Zbadaj czy system produkcji sadzonek
wpływa na biomasę korzeni oraz biomasę igieł 7-letnich sosen?


```{r}
danec3 <- readr::read_csv('danec3.csv')
head(danec3)
```